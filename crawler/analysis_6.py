import os
import re
import urllib.request
import zipfile
import pandas as pd
import jieba
from collections import Counter
import matplotlib.pyplot as plt
from matplotlib import font_manager, rcParams
from wordcloud import WordCloud

# ===== å­—å‹è¨­å®š =====
font_dir = "./fonts"
os.makedirs(font_dir, exist_ok=True)
font_path = os.path.join(font_dir, "NotoSansCJK-Regular.ttc")

if not os.path.exists(font_path):
    print("ğŸ“¥ æ­£åœ¨ä¸‹è¼‰ Noto ä¸­æ–‡å­—å‹...")
    url = "https://noto-website-2.storage.googleapis.com/pkgs/NotoSansCJKtc-hinted.zip"
    zip_path = os.path.join(font_dir, "NotoSansCJKtc.zip")
    urllib.request.urlretrieve(url, zip_path)
    with zipfile.ZipFile(zip_path, "r") as zip_ref:
        zip_ref.extractall(font_dir)
    os.remove(zip_path)
    for file in os.listdir(font_dir):
        if file.endswith(".ttc"):
            font_path = os.path.join(font_dir, file)
            break
    print(f"âœ… å­—å‹å·²ä¸‹è¼‰ä¸¦è¨­ç½®ï¼š{font_path}")

my_font = font_manager.FontProperties(fname=font_path)
rcParams["font.sans-serif"] = [font_path]
rcParams["axes.unicode_minus"] = False

# ===== è®€å–è³‡æ–™ =====
df = pd.read_csv("output/ptt_stock_articles.csv")
df[["æ¨æ–‡æ•¸é‡", "å™“æ–‡æ•¸é‡", "ç®­é ­æ•¸é‡"]] = df[["æ¨æ–‡æ•¸é‡", "å™“æ–‡æ•¸é‡", "ç®­é ­æ•¸é‡"]].fillna(0)
df["äº’å‹•ç¸½æ•¸"] = df["æ¨æ–‡æ•¸é‡"] + df["å™“æ–‡æ•¸é‡"] + df["ç®­é ­æ•¸é‡"]

print("æœ€ç†±é–€æ–‡ç« ï¼š")
print(df.sort_values("äº’å‹•ç¸½æ•¸", ascending=False).head())

# ===== é¸æ“‡ç†±é–€æ–‡ç«  =====
# ä»¥äº’å‹•ç¸½æ•¸å‰10%ç‚ºç†±é–€æ–‡ç« 
threshold = df["äº’å‹•ç¸½æ•¸"].quantile(0.9)
df_hot = df[df["äº’å‹•ç¸½æ•¸"] >= threshold]

# ===== æ¸…ç†å…§æ–‡ =====
def clean_text(text):
    text = re.sub(r"\d{1,4}[/-]\d{1,2}[/-]\d{1,2}", " ", text)  # æ—¥æœŸ
    text = re.sub(r"\d{1,2}:\d{2}", " ", text)                  # æ™‚é–“
    text = re.sub(r"[0-9]+", " ", text)                         # æ•¸å­—
    text = re.sub(r"[A-Za-z]+", " ", text)                     # è‹±æ–‡å­—æ¯
    return text

df_hot["å…§æ–‡_clean"] = df_hot["å…§æ–‡"].astype(str).apply(clean_text)
text = " ".join(df_hot["å…§æ–‡_clean"])
words = jieba.lcut(text)
word_counts = Counter(words)

# ===== åœç”¨è©è¨­å®š =====
stopwords = set([
    "çš„","äº†","æ˜¯","åœ¨","æˆ‘","æœ‰","å°±","ä¸","ä¹Ÿ","äºº","éƒ½","é‚„",
    "èˆ‡","èˆ‡å…¶","è¢«","ä½ ","ä»–","å¥¹","æˆ‘å€‘","è‡ªå·±","é€™","é‚£"
])

# å‹•æ…‹åµæ¸¬é«˜é »ç„¡æ„ç¾©è©
total_unique_words = len(word_counts)
top_percent = 0.01
num_top = max(1, int(total_unique_words * top_percent))
sorted_words = word_counts.most_common()
high_freq_words = [w for w, c in sorted_words[:num_top] if len(w) <= 2]
stopwords.update(high_freq_words)

filtered = {w: c for w, c in word_counts.items() if w not in stopwords and len(w) > 1}

print("ç†±é–€æ–‡ç« é«˜é »è©ï¼š", Counter(filtered).most_common(20))
print(f"è‡ªå‹•åŠ å…¥åœç”¨è©ï¼ˆå‰1%é«˜é »çŸ­è©ï¼‰ï¼š{high_freq_words}")

# ===== ç”¢ç”Ÿç†±é–€æ–‡ç« è©é›² =====
wc = WordCloud(
    font_path=font_path,
    width=800,
    height=400,
    background_color="white"
)
wc.generate_from_frequencies(filtered)

plt.figure(figsize=(10, 5))
plt.imshow(wc, interpolation="bilinear")
plt.axis("off")
plt.tight_layout()
plt.savefig("hot_wordcloud.png", dpi=300)
print("âœ… ç†±é–€æ–‡ç« è©é›²å·²å­˜æˆï¼šhot_wordcloud.png")

# ===== æ¨/å™“/ç®­é ­æ¯”ä¾‹é•·æ¢åœ– =====
plt.figure(figsize=(8, 6))
counts = [df["æ¨æ–‡æ•¸é‡"].sum(), df["å™“æ–‡æ•¸é‡"].sum(), df["ç®­é ­æ•¸é‡"].sum()]
labels = ["æ¨æ–‡", "å™“æ–‡", "ç®­é ­"]
colors = ["green", "red", "gray"]

bars = plt.bar(labels, counts, color=colors)
for bar, count in zip(bars, counts):
    plt.text(bar.get_x() + bar.get_width()/2, count + max(counts)*0.01, str(int(count)),
             ha='center', fontproperties=my_font)

plt.title("PTT Stock ç‰ˆ æ¨/å™“/ç®­é ­ ç¸½æ•¸é‡", fontproperties=my_font)
plt.ylabel("æ•¸é‡", fontproperties=my_font)
plt.tight_layout()
plt.savefig("push_boo_chart.png", dpi=300)
print("âœ… æ¨å™“æ–‡æ¯”ä¾‹é•·æ¢åœ–å·²å­˜æˆï¼špush_boo_chart.png")

plt.show()
